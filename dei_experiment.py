# -*- coding: utf-8 -*-
"""DEI_Experiment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12o2kSYRg2owPvsOpKtcvzQ11Mjwfg9as

**Experiemnt**: Extract the name from a Resume

Approach 1: Using NLTK
"""

# Commented out IPython magic to ensure Python compatibility.
!pip install nltk
!pip install pdfminer.six
!pip install ipython-autotime

# %load_ext autotime
from pdfminer.high_level import extract_text
import nltk

nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
nltk.download('maxent_ne_chunker')
nltk.download('words')

def extract_text_from_pdf(pdf_path):
    return extract_text(pdf_path)

def extract_name(txt):
    person_names = []
 
    for sent in nltk.sent_tokenize(txt):
        for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):
            if hasattr(chunk, 'label') and chunk.label() == 'PERSON':
                person_names.append(
                    ' '.join(chunk_leave[0] for chunk_leave in chunk.leaves())
                )
 
    return person_names[0]
 
if __name__ == '__main__':
    resume_text = extract_text_from_pdf('/content/STEM-Resume.pdf')
    print('Name: ',extract_name(resume_text))

"""Approach2: Using spaCy"""

!pip install pdfminer.six

from pdfminer.high_level import extract_text
import spacy
import en_core_web_sm
from spacy.matcher import Matcher

# load pre-trained model
nlp = en_core_web_sm.load()

# initialize matcher with a vocab
matcher = Matcher(nlp.vocab)

def extract_name(resume_text):
    nlp_text = nlp(resume_text)
    
    pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]
    matcher.add('NAME', None, pattern)
    matches = matcher(nlp_text)
    
    for match_id, start, end in matches:
        span = nlp_text[start:end]
        return span.text

if __name__ == '__main__':
    resume_text = extract_text_from_pdf('/content/STEM-Resume.pdf')
    print('Name: ',extract_name(resume_text))